{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c57e232-bc7a-4506-b4fc-9ea675619357",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pdfplumber\n",
    "from sqlalchemy import create_engine\n",
    "import json\n",
    "from datetime import datetime, date, timezone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92b64e92-5eec-4792-a552-c8a47b81623a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv()   \n",
    "\n",
    "DB_HOST = os.getenv(\"DB_HOST\")\n",
    "DB_NAME = os.getenv(\"DB_NAME\")\n",
    "DB_USER = os.getenv(\"DB_USER\")\n",
    "DB_PASSWORD = os.getenv(\"DB_PASSWORD\")\n",
    "\n",
    "\n",
    "engine = create_engine(\n",
    "    f\"mysql+mysqlconnector://{DB_USER}:{DB_PASSWORD}@{DB_HOST}/{DB_NAME}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47115ed8-6881-458c-ac56-c63a04f0aca8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CODE OF BUSINESS PRINCIPLES - unilever.pdf  done successfully\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cannot set gray non-stroke color because /'P190' is an invalid float value\n",
      "Cannot set gray non-stroke color because /'P449' is an invalid float value\n",
      "Cannot set gray non-stroke color because /'P562' is an invalid float value\n",
      "Cannot set gray non-stroke color because /'P604' is an invalid float value\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "codeofconduct-infosys.pdf  done successfully\n",
      "corp-governance-report-2024-nestle.pdf  done successfully\n",
      "corporate-governance-report-infosys.pdf  done successfully\n",
      "corporate-governance-report-wipro.pdf  done successfully\n",
      "HR Policy Manual 2023 iima.pdf  done successfully\n",
      "IIA HR Policy.pdf  done successfully\n",
      "infosys-ar-24.pdf  done successfully\n",
      "infosys-ar-25.pdf  done successfully\n",
      "tata-ar-24.pdf  done successfully\n"
     ]
    }
   ],
   "source": [
    "#Unstructured data\n",
    "pdf_folder = \"data/unstructured\"\n",
    "\n",
    "for pdf_file in os.listdir(pdf_folder):\n",
    "    if pdf_file.endswith(\".pdf\"):\n",
    "        with pdfplumber.open(os.path.join(pdf_folder, pdf_file)) as pdf:\n",
    "            text = \"\\n\".join(\n",
    "                page.extract_text() or \"\" for page in pdf.pages\n",
    "            )\n",
    "\n",
    "        df = pd.DataFrame([{\n",
    "            \"file_name\": pdf_file,\n",
    "            \"content\": text,\n",
    "            \"pages\": len(pdf.pages)\n",
    "        }])\n",
    "\n",
    "        df.to_sql(\"pdf\", engine, if_exists=\"append\", index=False)\n",
    "        print(pdf_file,\" done successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c4f9c1ad-a1c7-4b3e-859f-bd5e21b75556",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Structured data\n",
    "src_engine = create_engine(\n",
    "    f\"mysql+mysqlconnector://{DB_USER}:{DB_PASSWORD}@{DB_HOST}/sample_enterprise \"\n",
    ")\n",
    "\n",
    "tables = [\n",
    "    \"customer\",\n",
    "    \"department\",\n",
    "    \"employee\",\n",
    "    \"employee_project\",\n",
    "    \"manager\",\n",
    "    \"order_items\",\n",
    "    \"orders\",\n",
    "    \"product\",\n",
    "    \"project\"\n",
    "]\n",
    "\n",
    "for table in tables:\n",
    "    df = pd.read_sql(f\"SELECT * FROM {table}\", src_engine)\n",
    "    df.to_sql(table, engine, if_exists=\"replace\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b81f62a-81f2-417d-bfb3-5fa9d405134d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing customer_support_tickets.csv → Table: customer_support_tickets\n",
      "Processing emails.csv → Table: emails\n",
      "Processing glassdoor-companies-reviews.csv → Table: glassdoor-companies-reviews\n",
      "Processing Tata_Motors_Employee_Reviews.csv → Table: tata_motors_employee_reviews\n"
     ]
    }
   ],
   "source": [
    "#Semi structured data\n",
    "from sqlalchemy.dialects.mysql import LONGTEXT\n",
    "\n",
    "CHUNK_SIZE = 10_000\n",
    "CSV_FOLDER = \"data/semi structured\"\n",
    "\n",
    "def handle_nulls(df):\n",
    "    for col in df.columns:\n",
    "        col_lower = col.lower()\n",
    "\n",
    "        # Skip ID columns\n",
    "        if col_lower == \"id\" or col_lower.endswith(\"_id\"):\n",
    "            continue\n",
    "\n",
    "        # Numeric columns\n",
    "        if pd.api.types.is_numeric_dtype(df[col]):\n",
    "            median = df[col].median()\n",
    "            if not pd.isna(median):\n",
    "                df[col] = df[col].fillna(median)\n",
    "\n",
    "        # Datetime columns\n",
    "        elif pd.api.types.is_datetime64_any_dtype(df[col]):\n",
    "            df[col] = df[col].fillna(pd.NaT)\n",
    "\n",
    "        # Text / categorical\n",
    "        else:\n",
    "            df[col] = df[col].fillna(\"Unknown\")\n",
    "\n",
    "    return df\n",
    "\n",
    "for file in os.listdir(CSV_FOLDER):\n",
    "    if file.endswith(\".csv\"):\n",
    "\n",
    "        file_path = os.path.join(CSV_FOLDER, file)\n",
    "        table_name = file.replace(\".csv\", \"\").lower()\n",
    "\n",
    "        print(f\"Processing {file} → Table: {table_name}\")\n",
    "\n",
    "        first_chunk = True\n",
    "\n",
    "        for chunk in pd.read_csv(file_path, chunksize=CHUNK_SIZE):\n",
    "\n",
    "            chunk = handle_nulls(chunk)\n",
    "            chunk = chunk.replace({np.nan: None})\n",
    "\n",
    "            chunk.to_sql(\n",
    "                table_name,\n",
    "                engine,\n",
    "                if_exists=\"replace\" if first_chunk else \"append\",\n",
    "                index=False,dtype={\n",
    "                col: LONGTEXT()\n",
    "                for col in chunk.columns\n",
    "                if chunk[col].dtype == \"object\"\n",
    "            }\n",
    "            )\n",
    "\n",
    "            first_chunk = False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f8d25a1-7a36-4c86-96a3-f46e30aff440",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Converting to JSON\n",
    "def mysql_to_json(\n",
    "    engine,\n",
    "    output_file=\"outputs/ingested.json\",\n",
    "    chunk_size=1000\n",
    "):\n",
    "    tables = pd.read_sql(\"SHOW TABLES\", engine).iloc[:, 0].tolist()\n",
    "    first_record = True\n",
    "    record_id = 1\n",
    "\n",
    "    with open(output_file, \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(\"[\\n\")\n",
    "\n",
    "        for table in tables:\n",
    "            query = f\"SELECT * FROM `{table}`\"\n",
    "\n",
    "            for chunk in pd.read_sql(query, engine, chunksize=chunk_size):\n",
    "                for _, row in chunk.iterrows():\n",
    "                    row_data = {}\n",
    "\n",
    "                    for column, value in row.items():\n",
    "                        # Convert date/datetime to ISO string\n",
    "                        if isinstance(value, (datetime, date)):\n",
    "                            row_data[column] = value.isoformat()\n",
    "                        else:\n",
    "                            row_data[column] = value\n",
    "\n",
    "                    record = {\n",
    "                        \"id\": record_id,\n",
    "                        \"source_name\": table,\n",
    "                        \"timestamp\": datetime.now(timezone.utc).isoformat(),\n",
    "                        \"data\": row_data\n",
    "                    }\n",
    "\n",
    "                    if not first_record:\n",
    "                        f.write(\",\\n\")\n",
    "                    else:\n",
    "                        first_record = False\n",
    "\n",
    "                    json.dump(record, f, ensure_ascii=False)\n",
    "                    record_id += 1\n",
    "\n",
    "            print(f\"{table} done\")\n",
    "\n",
    "        f.write(\"\\n]\")\n",
    "\n",
    "    print(\"MySQL data successfully stored as JSON\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
