{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "187c56d5-ec72-47ad-89b3-c74e6a97c052",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import faiss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "427cea57-8cb5-4c91-a388-028f536fc81f",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = r\"outputs/normalized_output.json\"\n",
    "\n",
    "documents = []\n",
    "with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "    raw = f.read().strip()\n",
    "\n",
    "# Remove trailing commas safely\n",
    "raw = raw.rstrip(\",\")\n",
    "\n",
    "# Wrap as JSON array\n",
    "raw = \"[\" + raw + \"]\"\n",
    "\n",
    "documents = json.loads(raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8910698-3407-43f2-bc12-a473bcb3dc2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Flattened documents: 537812\n"
     ]
    }
   ],
   "source": [
    "# Flatten nested list if needed\n",
    "if isinstance(documents[0], list):\n",
    "    documents = [item for sublist in documents for item in sublist]\n",
    "\n",
    "print(\"Flattened documents:\", len(documents))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "99c09d36-d27c-40b7-9622-6c493aa430a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chunk data\n",
    "splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=800,\n",
    "    chunk_overlap=100\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8dceec11-806f-4f4c-8800-1225768f8296",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Embedding model\n",
    "model = SentenceTransformer(\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "all_embeddings = []\n",
    "metadata = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "def18f55-cd15-4eb9-9c3b-f43eb16dc6bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 512\n",
    "\n",
    "all_embeddings = []\n",
    "metadata_file = \"outputs/metadata.jsonl\"\n",
    "open(metadata_file, \"w\").close()\n",
    "\n",
    "batch_texts = []\n",
    "batch_meta = []\n",
    "\n",
    "# Processing\n",
    "for i, doc in enumerate(documents, start=1):\n",
    "    text = \" \".join([f\"{k}: {v}\" for k, v in doc[\"data\"].items()])\n",
    "    chunks = splitter.split_text(text)\n",
    "\n",
    "    for chunk in chunks:\n",
    "        batch_texts.append(chunk)\n",
    "        batch_meta.append({\n",
    "            \"chunk_text\": chunk,\n",
    "            \"record_id\": doc[\"id\"],\n",
    "            \"source_name\": doc[\"source_name\"],\n",
    "            \"timestamp\": doc[\"timestamp\"]\n",
    "        })\n",
    "\n",
    "    if len(batch_texts) >= BATCH_SIZE:\n",
    "        embeddings = model.encode(\n",
    "            batch_texts,\n",
    "            batch_size=128,\n",
    "            convert_to_numpy=True,\n",
    "            show_progress_bar=False\n",
    "        )\n",
    "\n",
    "        all_embeddings.append(embeddings)\n",
    "\n",
    "        with open(metadata_file, \"a\", encoding=\"utf-8\") as f:\n",
    "            for m in batch_meta:\n",
    "                f.write(json.dumps(m) + \"\\n\")\n",
    "\n",
    "        batch_texts.clear()\n",
    "        batch_meta.clear()\n",
    "\n",
    "    if i % 5000 == 0:\n",
    "        print(f\"Completed {i} records\")\n",
    "\n",
    "# Flush remaining\n",
    "if batch_texts:\n",
    "    embeddings = model.encode(batch_texts, batch_size=128, convert_to_numpy=True)\n",
    "    all_embeddings.append(embeddings)\n",
    "\n",
    "    with open(metadata_file, \"a\", encoding=\"utf-8\") as f:\n",
    "        for m in batch_meta:\n",
    "            f.write(json.dumps(m) + \"\\n\")\n",
    "print(\"Completed\")\n",
    "\n",
    "# Save embeddings\n",
    "final_embeddings = np.vstack(all_embeddings).astype(\"float32\")\n",
    "np.save(\"outputs/embeddings.npy\", final_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "732a0b21-1cc4-4637-a7bb-99f4a5eee78c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load metadata from .jsonl file\n",
    "metadata = []\n",
    "with open(\"outputs/metadata.jsonl\", \"r\", encoding=\"utf-8\") as f:\n",
    "    for line in f:\n",
    "        metadata.append(json.loads(line))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b006d194-bfa8-4990-add3-f7d1db731cdd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stored 2541581 embeddings in FAISS\n"
     ]
    }
   ],
   "source": [
    "# Create FAISS index\n",
    "dimension = all_embeddings.shape[1]\n",
    "index = faiss.IndexFlatL2(dimension)\n",
    "index.add(all_embeddings)\n",
    "\n",
    "# Save FAISS index\n",
    "faiss.write_index(index, \"vector_index.faiss\")\n",
    "\n",
    "# Save metadata as normal JSON (optional but useful)\n",
    "with open(\"outputs/metadata.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(metadata, f, indent=2)\n",
    "\n",
    "print(f\"Stored {all_embeddings.shape[0]} embeddings in FAISS\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c81c3632-3083-4cdf-81dc-e2682b09f234",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of vectors: 2541581\n",
      "Vector dimension: 384\n"
     ]
    }
   ],
   "source": [
    "# Load and verify FAISS index\n",
    "index = faiss.read_index(\"vector_index.faiss\")\n",
    "print(\"Number of vectors:\", index.ntotal)\n",
    "print(\"Vector dimension:\", index.d)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
